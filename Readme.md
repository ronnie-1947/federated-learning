# Project Federated learning
In this project, we are exploring the integration of differential privacy and federated learning to develop a framework for incorporating both techniques into any machine learning model. For testing, we use the MNIST dataset, a widely-used dataset consisting of 70,000 images of handwritten digits, which is ideal for training image classification models. Our approach includes preprocessing the dataset, partitioning it for federated learning scenarios, and implementing a neural network model to classify the digit images. By integrating differential privacy and homomorphic encryption, we aim to enhance data privacy and security while maintaining high model performance within a federated learning environment.

Our framework works as a client-server model, where clients and a central server collaboratively train a machine learning model while keeping data decentralized. Each client, which represents a local device or data holder, trains a local model on its subset of the data and periodically sends only the model updates (such as gradients or weights) to the central server. The server aggregates these updates to create a global model, which is then sent back to the clients for further training.

## Data preparation
In the data preparation step of our federated learning architecture, we start by separating the MNIST dataset into subsets, each representing a simulated client. This division enables us to effectively evaluate the federated learning process by simulating how data would be spread across several clients in a real-world setting. In reality, each client would already have its own training data, which would include multiple and perhaps heterogeneous datasets. By dividing the MNIST data into many client datasets, we can mimic the decentralized training environment and ensure that our framework appropriately represents the conditions under which federated learning functions.

For this purpose, we use a function called “prepare_dataset” from our library. This function takes any dataset and splits it into n parts for n clients in different ratios as needed (with equal parts as the default), effectively simulating a federated learning environment. Additionally, it utilizes PyTorch dataloaders to efficiently manage the data.

## Initiate server
Next step is to initiate the server. For this purpose, we use the `start_server` function from our federated library. This function accepts a server address (`host_addr`), the number of training rounds (`num_rounds`), and an optional strategy (`strategy`). If no strategy is provided, the function defaults to using the FedAvg (Federated Averaging) strategy. FedAvg is a commonly used algorithm in federated learning that combines model updates from multiple clients by averaging them. Within the function, if no custom strategy is specified, a weighted averaging function is defined to aggregate the accuracy metrics from each client based on the number of examples they used. This weighted average ensures that the global model's accuracy reflects the contributions of all clients proportionally. The function then configures the server with the specified number of rounds and chosen strategy, and starts the federated learning server at the given address using Flower (`fl`), a popular federated learning library.

## Define model
The next step is to define a machine learning model, which can be any model written in PyTorch. Our framework is designed to support any PyTorch-based model, ensuring flexibility and adaptability for various machine learning tasks. In the test code, we define a convolutional neural network (CNN) class `Net` for classifying the MNIST dataset. The model includes two convolutional layers, followed by max-pooling and three fully connected layers. The `train` function trains the model using the provided data loader, optimizer, and specified number of epochs. It leverages the cross-entropy loss function to compute the loss and performs backpropagation to update the model's parameters. The `test` function evaluates the model's performance by calculating the total loss and accuracy on the test dataset. During evaluation, the model is set to evaluation mode, and gradient calculations are disabled to save memory and computation.

## Initiate client
After model initialization, we are ready to prepare the client for federated learning. In our framework, we achieve this by utilizing the `fl_client` function, which integrates various components required for the client's participation in the federated learning process. The function takes several parameters, including the initialized model, the number of training epochs, the optimizer, the training and validation data loaders specific to the client, and the device configuration (e.g., CPU or GPU).

The `fl_client` function encapsulates these parameters into a client instance that is compatible with the Flower federated learning framework. It ensures that each client trains the model on its local data for the specified number of epochs, using the provided optimizer. The `train` and `test` functions are passed to handle the training and evaluation processes, respectively, ensuring that the client's model updates are correctly computed and assessed.This setup allows each client to independently train its local model and send updates to the central server, which aggregates these updates to improve the global model. 

## Incorporate differential privacy
The next stage in our framework is to create a privacy engine that incorporates differential privacy into the training process. We use the Opacus framework, a Facebook-developed library for training PyTorch models with differential privacy. Opacus assures that the model complies with privacy standards by adding noise to the gradients during training and clipping them to a specific norm, offering mathematical guarantees that individual data points cannot be easily retrieved from the trained model.

In the test code, we initialize a PrivacyEngine object from Opacus. This privacy engine is then used to modify the model, optimizer, and data loader to support differential privacy. The make_private method of PrivacyEngine is called with the model, optimizer, and data loader as arguments, along with two important hyperparameters: noise_multiplier and max_grad_norm. The noise_multiplier controls how much noise is introduced to the gradients to mask the effect of individual data points, while max_grad_norm specifies a threshold for gradient clipping, preventing any single gradient from having too much influence on the model update.

## Train model
The last step is to start training. We use the start_client function from our library. This function connects the prepared client to the federated learning server and begins the learning process. 

To automate the process, we wrote a shell script `run.sh` to train three clients.